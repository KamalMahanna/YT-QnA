{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'included': ['documents'],\n",
       " 'data': None,\n",
       " 'metadatas': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DataBases.VectorStore import VectorStore\n",
    "\n",
    "vector_store = VectorStore(\"AIzaSyBqfX2X2X2X2X2X2X2X2X2X2X2X2X2X2X\")\n",
    "\n",
    "vector_store.collection.get(where={\"youtube_id\": \"5YP7GOeFTCY\"}, include=[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.LLM import GeminiLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GeminiLLM(os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.TextLLM(\"you are a helpfull assistant\", [{\"role\": \"user\", \"parts\": [{\"text\": \"hello\"}]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a large language model, trained by Google.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.send_message(\"who are you\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Transcript import Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = Transcript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisp_api = transcript.with_whisper(os.getenv(\"GROQ_API_KEY\"), \"2nNGN72eYiU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = client.chats.create(model=\"gemini-2.5-flash-preview-05-20\",\n",
    "history=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [{\"text\": \"Hello, how are you?\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [{\"text\": \"I'm a large language model, trained by google.\"}]\n",
    "    }\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.send_message(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../.env\")\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "result = client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents=[\"What is the meaning of life?\",\"for real?\"],\n",
    "        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    ")\n",
    "print(result.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.values for i in result.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ListModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Transcript import Transcript\n",
    "transcript = Transcript()\n",
    "texts = transcript.with_youtube_api(\"5YP7GOeFTCY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texts.txt','w+') as f:\n",
    "    for i in texts[:10]:\n",
    "        f.write(i['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(\" \".join([text['text'] for text in texts[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "filename = \"/tmp/tmp6g5jvppl.m4a\"\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      file=(filename, file.read()), \n",
    "      language=\"en\",\n",
    "      model=\"whisper-large-v3-turbo\",\n",
    "      response_format=\"verbose_json\",\n",
    "    )\n",
    "    print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription.segments[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription.segments[0]['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "paths = ['/tmp/tmp5ydyyyv4.m4a','/tmp/tmpggun29z0.m4a','/tmp/tmp30meyr1c.m4a']\n",
    "for path in paths:\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from utils.Translator import translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Transcript import Transcript\n",
    "\n",
    "transcript = Transcript()\n",
    "texts = transcript.with_whisper(\"2nNGN72eYiU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texts.txt','w') as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_texts = asyncio.run(translate_text(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path=\"/tmp/tmpe9wob2yo.mp4\"\n",
    "if output_path:\n",
    "    if not os.path.isabs(output_path):\n",
    "        output_path = os.path.join(os.getcwd(), output_path)\n",
    "else:\n",
    "    output_path = os.getcwd()\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "import tempfile\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=\" + \"5YP7GOeFTCY\"\n",
    "yt = YouTube(url)\n",
    "audio_stream = yt.streams.filter(only_audio=True,abr=\"128kbps\")\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_audio:\n",
    "\n",
    "    directory = temp_audio.name.split(\"/\")\n",
    "    \n",
    "    audio_stream.first().download(filename = directory[-1],output_path = \"/\"+directory[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_audio.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filetype\n",
    "\n",
    "kind = filetype.guess(temp_audio.name)\n",
    "if kind:\n",
    "    print(f\"Detected type: {kind.mime}, extension: {kind.extension}\")\n",
    "else:\n",
    "    print(\"File type could not be determined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.getsize(temp_audio.name) == 0:\n",
    "    print(\"File is empty.\")\n",
    "else:\n",
    "    print(\"File is not empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import magic\n",
    "\n",
    "file_path = temp_audio.name\n",
    "\n",
    "# Create a Magic object\n",
    "mime = magic.Magic(mime=True)\n",
    "mime.from_file('tmptmpxdexbsq8.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "display(Audio(filename=temp_audio.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "url = \"https://www.youtube.com/watch?v=\"+\"0zhPaRZev8w\"\n",
    "yt = YouTube(url)\n",
    "audio_stream = yt.streams.filter(only_audio=True,abr=\"128kbps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.first().download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# Replace with the YouTube video ID\n",
    "video_id = \"ZPUtA3W-7_I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytt_api = YouTubeTranscriptApi()\n",
    "# transcript_list = ytt_api.fetch(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytt_api = YouTubeTranscriptApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transcript_list = ytt_api.get_transcript(video_id,languages=[\"en\",'hi'])\n",
    "print(transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind_transcript = ytt_api.get_transcript(\"giqjHxdN-Ok\",languages=[\"en\",'hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind_transcript[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \" \".join([i['text'] for i in hind_transcript[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=\"नमस्कार वेलकम टू करियर 247 मैं हूं प्रशांत धवन कभी 2 बिलियन डॉल के न्यूक्लियर बमबर्स 30 सेकंड में डिस्ट्रॉय होते हुए देखे हैं नहीं देखे मैं आपको दिखाता हूं इधर आप देख पाओगे यह फुटेज पूरी दुनिया में वायरल हो रही है। नीचे जो यह प्लेन दिख रहे हैं ना यह न्यूक्लियर स्ट्रेटेजिक बमबर्स हैं। ऐसा कोई भी प्लेन भारत के पास नहीं है। गिनती के दो-तीन कंट्रीज के पास ऐसे बमबर्स हैं और यूक्रेन\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Example text in another language (e.g., Hindi)\n",
    "\n",
    "# Translate to English\n",
    "translated = translator.translate(texts, dest='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import asyncio\n",
    "async def translate_text(texts):\n",
    "    async with Translator() as translator:\n",
    "        result = await translator.translate(texts)\n",
    "        print(result)  # <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>\n",
    "asyncio.run(translate_text(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in translated:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ = \"\"\n",
    "for i in transcript_list:\n",
    "    temp_ += i['text']\n",
    "len(temp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[True for i in temp_.split(\". \") if len(i) > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "68.76+3.719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 300\n",
    "chunks = []\n",
    "timestamps = []\n",
    "\n",
    "chunk_stack = \"\"\n",
    "timestamp_stack = \"\"\n",
    "\n",
    "for i in transcript_list:\n",
    "    the_text = i['text'].strip()\n",
    "    the_timestamp = i['start']\n",
    "        \n",
    "    # if the text is longer than the chunk size\n",
    "    if len(the_text) >= chunk_size:\n",
    "\n",
    "        # if previously any chunks exist, append them to the list\n",
    "        if chunk_stack:\n",
    "            chunks.append(chunk_stack)\n",
    "            timestamps.append(timestamp_stack)\n",
    "\n",
    "            # reset the stack\n",
    "            chunk_stack = \"\"\n",
    "            timestamp_stack = 0\n",
    "\n",
    "        # append the current chunk\n",
    "        chunks.append(the_text)\n",
    "        timestamps.append(the_timestamp)\n",
    "\n",
    "\n",
    "    # if the text is shorter than the chunk size\n",
    "    else:\n",
    "        \n",
    "        # if chunk and text combined is longer than the chunk size\n",
    "        if len(chunk_stack := chunk_stack + \" \" + the_text) > chunk_size:\n",
    "            \n",
    "            # split the chunk stack into sentences\n",
    "            splits = chunk_stack.split(\". \")\n",
    "            temp_chunk_stack = \"\"\n",
    "            \n",
    "            # while the chunk stack is longer than the chunk size\n",
    "            while(len(chunk_stack := \". \".join(splits)) > chunk_size):\n",
    "                \n",
    "                # pop the last sentence from the splits and add it to the temp chunk stack\n",
    "                temp_chunk_stack = splits.pop() + \". \" + temp_chunk_stack\n",
    "            \n",
    "            # append the chunk stack and timestamp when the chunk stack is shorter than the chunk size\n",
    "            chunks.append(chunk_stack.strip())\n",
    "            timestamps.append(timestamp_stack)\n",
    "\n",
    "            # reset the stack to temp chunk stack\n",
    "            chunk_stack = temp_chunk_stack\n",
    "\n",
    "        # always update the timestamp    \n",
    "        timestamp_stack = the_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.PersistentClient(\"./my_chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating embeddings\n",
    "\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=gemini_api_key)\n",
    "\n",
    "class GeminiEmbedding:\n",
    "    def __call__(self, input):\n",
    "        result = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input)\n",
    "\n",
    "        return [e.values for e in result.embeddings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(\"youtube_transcripts\",embedding_function=GeminiEmbedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "chunks_len = len(chunks)\n",
    "for i in range(0,chunks_len,100):\n",
    "\n",
    "    collection.add(\n",
    "        documents=chunks[i:i+100],\n",
    "        ids=[str(uuid.uuid4()) for _ in range(100 if chunks_len >= 100 else chunks_len%100)],\n",
    "        metadatas=[{\n",
    "            \"time_stamp\": t,\n",
    "            \"youtube_id\": video_id,\n",
    "        } for t in timestamps[i:i+100] ]\n",
    "    )\n",
    "    chunks_len -= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collection.get()['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii = collection.query( query_texts='pollution in India').embeddings[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query( query_texts='pollution in India', n_results=5).get('documents','metadatas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents='who are you').embeddings[0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
